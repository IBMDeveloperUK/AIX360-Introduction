{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Data and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://aix360.mybluemix.net/static/images/methods-choice.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do you want to understand?\n",
    "\n",
    "### Global explanation of data \n",
    "\n",
    "* [Health and Lifestyle Survey (CDC)](#CDC)\n",
    "  * [Summarize Income Questionnaire using Prototypes](#summarize-questionnaire) (ProtoDash)\n",
    "\n",
    "### Local explanation of a model\n",
    "\n",
    "* [Health and Lifestyle Survey (CDC)](#CDC)\n",
    "  * [Find Questionnaires that are most representative of Income](#find-questionnaire) (ProtoDash)\n",
    "* [IRIS](#IRIS)\n",
    "  * knn classification - [Explain a single prediction](#explain-single-shap) (SHAP)\n",
    "* [Employee Retention](#retention)\n",
    "  * [Explain a single prediction](#ted1) (TED)\n",
    "  \n",
    "### Global explanation of a model\n",
    "\n",
    "* [IRIS](#IRIS)\n",
    "  * [Explain all predictions](#explain-all-shap) (SHAP)\n",
    "* [Employee Retention](#retention)\n",
    "  * [Overall model accuracy](#ted2) (TED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy --upgrade\n",
    "!pip install aix360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When there are errors when running the below, restart kernel and run the cell below again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "from sklearn import svm     \n",
    "import time\n",
    "np.random.seed(1)\n",
    "\n",
    "from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from aix360.algorithms.ted.TED_Cartesian import TED_CartesianExplainer\n",
    "from aix360.algorithms.shap import KernelExplainer\n",
    "from aix360.datasets.cdc_dataset import CDCDataset\n",
    "from aix360.datasets.ted_dataset import TEDDataset\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"CDC\"></a>\n",
    "# Understanding data - Health and Lifestyle Survey\n",
    "\n",
    "The [NHANES CDC questionnaire datasets](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&CycleBeginYear=2013) are surveys conducted by the organization involving thousands of civilians about their daily lives. There are 44 questionnaires that collect data about income, occupation, health, early childhood and many other behavioral and lifestyle aspects of individuals living in the US. \n",
    "\n",
    "### [Protodash: Fast Interpretable Prototype Selection](https://arxiv.org/abs/1707.01212)\n",
    "\n",
    "* The method takes as input a datapoint (or group of datapoints) to be explained with respect to points in a training set belonging to the same feature space\n",
    "* The method then tries to minimize the maximum mean discrepancy (MMD metric) between the datapoints we want to explain and a prespecified number of instances from the training set that it will select. It will try to select training instances that have the same distribution as the datapoints we want to explain\n",
    "* The method has quality guarantees with it, returning importance weights for the chosen prototypical training instances indicative of how similar/representative they are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "This dataset is baked into aix360, which makes it easy to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhanes = CDCDataset()\n",
    "nhanes_files = nhanes.get_csv_file_names()\n",
    "(nhanesinfo, _, _) = nhanes._cdc_files_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column in the dataset corresponds to a question and each row are the answers given by a respondent to those questions. Both column names and answers by respondents are encoded. For example, 'SEQN' denotes the sequence number assigned to a respondent and 'IND235' corresponds to a question about monthly family income. In most cases a value of 1 implies \"Yes\" to the question, while a value of 2 implies \"No.\" More details about the income questionaire and how questions and answers are encoded is [here](https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/INQ_H.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace encoded column names by the associated question text. \n",
    "df_inc = nhanes.get_csv_file('INQ_H.csv')\n",
    "df_inc.columns[0]\n",
    "dict_inc = {\n",
    "'SEQN': 'Respondent sequence number', \n",
    "'INQ020': 'Income from wages/salaries',\n",
    "'INQ012': 'Income from self employment',\n",
    "'INQ030':'Income from Social Security or RR',\n",
    "'INQ060':  'Income from other disability pension', \n",
    "'INQ080':  'Income from retirement/survivor pension',\n",
    "'INQ090':  'Income from Supplemental Security Income',\n",
    "'INQ132':  'Income from state/county cash assistance', \n",
    "'INQ140':  'Income from interest/dividends or rental', \n",
    "'INQ150':  'Income from other sources',\n",
    "'IND235':  'Monthly family income',\n",
    "'INDFMMPI':  'Family monthly poverty level index', \n",
    "'INDFMMPC':  'Family monthly poverty level category',\n",
    "'INQ244':  'Family has savings more than $5000',\n",
    "'IND247':  'Total savings/cash assets for the family'\n",
    "}\n",
    "qlist = []\n",
    "for i in range(len(df_inc.columns)):\n",
    "    qlist.append(dict_inc[df_inc.columns[i]])\n",
    "df_inc.columns = qlist\n",
    "print(\"Answers given by some respondents to the income questionnaire:\")\n",
    "df_inc.head(5).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of respondents to Income questionnaire:\", df_inc.shape[0])\n",
    "print(\"Distribution of answers to \\'monthly family income\\' and \\'Family savings\\' questions:\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "hist1 = df_inc['Monthly family income'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "hist2 = df_inc['Family has savings more than $5000'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The majority of individuals responded with a \"12\" for the question related to monthly family income, which means their income is above USD 8400 as explained [here](https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/INQ_H.htm#IND235)\n",
    "* To the question of whether the family has savings of more than USD 5000, the majority of individuals responded with a \"2\", which means \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summarize-questionnaire\"></a>\n",
    "## Summarize Income Questionnaire using Prototypes\n",
    "\n",
    "Consider a social scientist who would like to quickly obtain a summary report of this dataset in terms of types of people that span this dataset. Is it possible to summarize this dataset by looking at answers given by a few representative/prototypical respondents? \n",
    "\n",
    "The Protodash algorithm can be used to obtain a few prototypical respondents (about 10 in this example) that span the diverse set of individuals answering the income questionnaire making it easy to summarize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframe to numpy\n",
    "data = df_inc.to_numpy()\n",
    "\n",
    "#sort the rows by sequence numbers in 1st column \n",
    "idx = np.argsort(data[:, 0])  \n",
    "data = data[idx, :]\n",
    "\n",
    "# replace nan's (missing values) with 0's\n",
    "original = data\n",
    "original[np.isnan(original)] = 0\n",
    "\n",
    "# delete 1st column (sequence numbers)\n",
    "original = original[:, 1:]\n",
    "\n",
    "print(original.shape)\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode all features as they are categorical\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onehot_encoded.shape)\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Protodash?\n",
    "\n",
    "Prototypes represent the different segments in a dataset\n",
    "* For example you might find that there are three categories of people: i) those that are high earners, ii) those that are middle class and iii) those that don't earn much or are unemployed and receive unemployment benefits\n",
    "* Protodash will find these segments by pointing to specific individuals that lie in these categories\n",
    "* From the objective function value of Protodash you are also able to say that three segments is the right number here as adding one more segment may not improve the objective value by much\n",
    "\n",
    "The ['ProtodashExplainer'](v) provides exemplar-based explanations for summarizing datasets as well as explaining predictions.\n",
    "\n",
    "* Input:  \n",
    "    * Dataset to select prototypical explanations from: `onehot_encoded`\n",
    "    * Dataset you want to explain: also `onehot_encoded`\n",
    "    * Number of prototypes `m`\n",
    "* Output:\n",
    "* Indices of the selected prototypes `S`\n",
    "* Importance weights associated with the selected prototypes `W`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "\n",
    "(W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=10) \n",
    "\n",
    "# sort the order of prototypes in set S\n",
    "idx = np.argsort(S)\n",
    "S = S[idx]\n",
    "W = W[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the prototypes along with their computed weights\n",
    "inc_prototypes = df_inc.iloc[S, :].copy()\n",
    "# Compute normalized importance weights for prototypes\n",
    "inc_prototypes[\"Weights of Prototypes\"] = np.around(W/np.sum(W), 2) \n",
    "inc_prototypes.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 people shown above (i.e. 10 prototypes) are representative of the income questionnaire according to Protodash. \n",
    "\n",
    "* In the distribution plot for family finance related questions, there roughly were five times as many people not having savings in excess of USD 5000 compared with others. The prototypes also have a similar spread, which is reassuring\n",
    "* For monthly family income, there is a more even spread over the more commonly occurring categories. This is a kind of spot check to see if our prototypes actually match the distribution of values in the dataset.\n",
    "* Most people are employed (3rd question) and work for an organization earning through salary/wages (1st two questions)\n",
    "* Most of them are also young (5th question) and fit to work (4th question)\n",
    "* They don't seem to have much savings (last question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"find-questionnaire\"></a>\n",
    "## Find Questionnaires that are most representative of Income\n",
    "\n",
    "How do the remaining 39 questionnaires represent or relate to income? The below will give an idea of which lifestyle factors are likely to affect income the most from prototypes for each of the questionnaires.\n",
    "\n",
    "### Compute prototypes for all questionaires\n",
    "\n",
    "This step uses Protodash explainer to compute 10 prototypes for each of the questionaires and saves these for further evaluation. (This takes a little while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all questionnaire datasets and find 10 prototypes for each.\n",
    "\n",
    "prototypes = {}\n",
    "\n",
    "for i in range(len(nhanes_files)):\n",
    "    \n",
    "    f = nhanes_files[i]\n",
    "    \n",
    "    print(\"processing \", f)\n",
    "    \n",
    "    # read data to pandas dataframe\n",
    "    df = nhanes.get_csv_file(f)\n",
    "    \n",
    "    # convert data to numpy\n",
    "    data = df.to_numpy()\n",
    "\n",
    "    #sort the rows by sequence numbers in 1st column \n",
    "    idx = np.argsort(data[:, 0])\n",
    "    data = data[idx, :]\n",
    "\n",
    "    # replace nan's with 0's.\n",
    "    original = data\n",
    "    original[np.isnan(original)] = 0\n",
    "\n",
    "    # delete 1st column (contains sequence numbers)\n",
    "    original = original[:, 1:]\n",
    "\n",
    "    # one hot encode all features as they are categorical\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(original)\n",
    "\n",
    "    explainer = ProtodashExplainer()\n",
    "\n",
    "    # call Protodash explainer\n",
    "    # S contains indices of the selected prototypes\n",
    "    # W contains importance weights associated with the selected prototypes \n",
    "\n",
    "    (W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=10) \n",
    "\n",
    "    prototypes[f]={}\n",
    "    prototypes[f]['W']= W\n",
    "    prototypes[f]['S']= S\n",
    "    prototypes[f]['data'] = data\n",
    "    prototypes[f]['original'] = original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the set of prototypical respondents from various questionaires using their income questionaire. \n",
    "\n",
    "How well do the prototypes of each questionaire represent the Income questionnaire based on the objective function that Protodash uses?\n",
    "\n",
    "By ranking the different questionnaires with their objective function values in ascending order. The higher a questionaire appears in the list, the better its prototypes represent the income questionaire. The values on the right indicate our objective value where lower value is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load income dataset INQ_H and its prototypes\n",
    "X = prototypes['INQ_H.csv']['original']\n",
    "Xdata = prototypes['INQ_H.csv']['data']\n",
    "\n",
    "# Iterate through all questionnaires and evaluate how well their prototypes represent the income dataset. \n",
    "objs = []\n",
    "for i in range(len(nhanes_files)):\n",
    "        \n",
    "    #load a dataset, its prototypes & weights\n",
    "\n",
    "    f = nhanes_files[i]\n",
    "    \n",
    "    Ydata = prototypes[f]['data']\n",
    "    S = prototypes[f]['S']\n",
    "    W = prototypes[f]['W']\n",
    "    \n",
    "    \n",
    "    # sort the order of prototypes in set S\n",
    "    idx = np.argsort(S)\n",
    "    S = S[idx]\n",
    "    W = W[idx]\n",
    "    \n",
    "    # access corresponding prototypes in X. \n",
    "    XS = X[np.isin(Xdata[:, 0], Ydata[S, 0]), :]\n",
    "    \n",
    "    #print(Ydata[S, 0])\n",
    "    #print(Xdata[np.isin(Xdata[:, 0], Ydata[S, 0]), 0])   \n",
    "    \n",
    "    temp = np.dot(XS, np.transpose(X))    \n",
    "    u = np.sum(temp, axis=1)/temp.shape[1]\n",
    "    \n",
    "    K = np.dot(XS, XS.T)\n",
    "    \n",
    "    # evaluate prototypes on income based on our objective function with dot product as similarity measure\n",
    "    obj = 0.5 * np.dot(np.dot(W.T, K), W) - np.dot(W.T, u)\n",
    "    objs.append(obj)    \n",
    "    \n",
    "\n",
    "# sort the objectives (ascending order) \n",
    "index = np.argsort(np.array(objs))\n",
    "\n",
    "# load the results in a dataframe to print\n",
    "evalresult = []\n",
    "for i in range(0,len(index)):    \n",
    "    evalresult.append([ nhanesinfo[index[i]], objs[index[i]] ])\n",
    "    \n",
    "    \n",
    "df_evalresult = pd.DataFrame.from_records(evalresult)\n",
    "df_evalresult.columns = ['Questionaire', 'Prototypes representative of Income']\n",
    "df_evalresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight from Protodash\n",
    "\n",
    "* Early childhood represents income the most. The early childhood questionnaire has information about the environment that the child was born and raised in\n",
    "* This is consistent with a [long term study](https://www.theatlantic.com/business/archive/2016/07/social-mobility-america/491240/) that talks about significant decrease in social mobility in recent times, stressing the fact that your childhood impacts how monetarily successful you are likely to be\n",
    "* Protodash was able to uncover this relationship with access to just these survey questionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"IRIS\"></a>\n",
    "# Understanding model predictions - IRIS\n",
    "\n",
    "There are two ways to use [SHAP](https://github.com/slundberg/shap) explainers after installing aix360. In this notebook they are invoked similarly to other explainer algorithms in aix360 via the implemented wrapper classes. But since SHAP comes pre-installed in aix360, the explainers can simply be invoked directly.\n",
    "\n",
    "<a class=\"anchor\" id=\"explain-single-shap\"></a>\n",
    "## Explain a single prediction\n",
    "\n",
    "An example with a K nearest neighbors ([knn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) classification of the IRIS dataset based on the [original SHAP tutorial](https://slundberg.github.io/shap/notebooks/Iris%20classification%20with%20scikit-learn.html).\n",
    "\n",
    "Learn more about SHAP in [this chapter](https://christophm.github.io/interpretable-ml-book/shap.html#shap-summary-plot) in the Interpretable Machine Learning by Christoph Molnar.\n",
    "\n",
    "The goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. Features with large absolute Shapley values are important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.datasets.iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\n",
    "\n",
    "def print_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "n_neighbors = 5   # default=5\n",
    "weights='uniform'  # 'uniform' or 'distance'\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "print_accuracy(knn.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability estimates\n",
    "knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapexplainer = KernelExplainer(knn.predict_proba, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(shapexplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aix360 style for explaining input instances\n",
    "shap_values = shapexplainer.explain_instance(X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The individual force plot\n",
    "\n",
    "Red/blue: Features that push the prediction higher (to the right) are shown in red, and those pushing the prediction lower are in blue.\n",
    "\n",
    "The plot is centered on the x-axis at explainer.expected_value. All SHAP values are relative to the model's expected value like a linear model's effects are relative to the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapexplainer.explainer.expected_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[23,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shapexplainer.explain_instance(X_test.iloc[23,:])\n",
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test.iloc[23,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"explain-all-shap\"></a>\n",
    "## Explain all predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_all = shapexplainer.explain_instance(X_test)\n",
    "shap.summary_plot(shap_values_all, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aix360 style for explaining input instances\n",
    "shap_values = shapexplainer.explain_instance(X_test)\n",
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"retention\"></a>\n",
    "# Employee Retention\n",
    "\n",
    "The **TED_CartesianExplainer** is an implementation of the algorithm in the AIES'19 paper by [Hind et al.]() It is most suited for use cases where matching explanations to the mental model of the explanation consumer is the highest priority; i.e., where the explanations are similar to what would be produced by a domain expert.\n",
    "\n",
    "There are many approaches to implementing this functionality. Below the **TED_CartesianExplainer** is used, which simply takes the Cartesian product of the label and explanation and creates a new label (YE) and uses this to train a (multiclass) classifier. \n",
    "\n",
    "### [A deck of cards](https://en.wikipedia.org/wiki/Cartesian_product)\n",
    "\n",
    "* An illustrative example is the standard 52-card deck\n",
    "* The standard playing card ranks {A, K, Q, J, 10, 9, 8, 7, 6, 5, 4, 3, 2} form a 13-element set\n",
    "* The card suits {♠, ♥, ♦, ♣} form a four-element set\n",
    "* The Cartesian product of these sets returns a 52-element set consisting of 52 ordered pairs, which correspond to all 52 possible playing cards.\n",
    "\n",
    "This simple cartesian product approach is quite general in that it can use any classifier (passed as a parameter), as long as it complies with the fit/predict paradigm.\n",
    "\n",
    "## Synthetic dataset\n",
    "\n",
    "A synthetically generated [dataset](https://github.com/IBM/AIX360/blob/master/aix360/data/ted_data/Retention.csv) is used with this [code](https://github.com/IBM/AIX360/blob/master/aix360/data/ted_data/GenerateData.py) that is part of aix360.\n",
    "\n",
    "### Assigning labels\n",
    "\n",
    "25 rules are created, for why a retention action is needed to reduce the chances of an employee choosing to leave our fictitious company. These rules are motivated by common scenarios, such as not getting a promotion in a while, not being paid competitively, receiving a disappointing evaluation, being a new employee in certain organizations with inherently high attrition, not having a salary that is consistent with positive evaluations, mid-career crisis, etc.   \n",
    "\n",
    "Each of these 25 rules would result in the label \"Yes\"; i.e., the employee is a risk to leave the company. Because the rules capture the reason for the \"Yes\", we use the rule number as the explanation (E), which is required by the TED framework.\n",
    "\n",
    "If none of the rules are satisfied, it means the employee is not a candidate for a retention action; i.e., a \"No\" label is assigned.  \n",
    "\n",
    "### Dataset characteristics\n",
    "\n",
    "10,000 fictious employees (X) are generated and the 26 (25 Yes + 1 No) rules are applied to produce Yes/No labels (Y), using these rules as explanations (E).  After applying these rules, the resulting dataset has the following characteristics:\n",
    "- Yes (33.8%)\n",
    "- No (66.2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a new TEDDataset object based on the \"Retention.csv\" file. The load_file method decomposes the dataset into its X, Y, and E components. (See [TEDDataset class](https://github.com/IBM/AIX360/blob/master/aix360/datasets/ted_dataset.py) for the expected format.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the dataset into X, Y, E     \n",
    "X, Y, E = TEDDataset().load_file('Retention.csv')\n",
    "print(\"X's shape:\", X.shape)\n",
    "print(\"Y's shape:\", Y.shape)\n",
    "print(\"E's shape:\", E.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition these instances into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train/test split\n",
    "X_train, X_test, Y_train, Y_test, E_train, E_test = train_test_split(X, Y, E, test_size=0.20, random_state=0)\n",
    "print(\"X_train shape:\", X_train.shape, \", X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape, \", Y_test shape:\", Y_test.shape)\n",
    "print(\"E_train shape:\", E_train.shape, \", E_test shape:\", E_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier and pass to TED_CartesianExplainer\n",
    "estimator = svm.SVC(kernel='linear')\n",
    "# estimator = DecisionTreeClassifier()\n",
    "# estimator = RandomForestClassifier()\n",
    "# estimator = AdaBoostClassifier()\n",
    "\n",
    "ted = TED_CartesianExplainer(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the classifier\")\n",
    "\n",
    "ted.fit(X_train, Y_train, E_train)   # train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ted1\"></a>\n",
    "## Explain a single prediction\n",
    "\n",
    "The trained TED classifier is now ready for predictions with explanations.   We construct some raw feature vectors, created from the original dataset, and ask for a label (Y) prediction and its explanation (E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance level example \n",
    "X1 = [[1, 2, -11, -3, -2, -2,  22, 22]]\n",
    "\n",
    "# correct answers:  Y:-10; E:13\n",
    "Y1, E1 = ted.predict_explain(X1)\n",
    "print(\"Predicting for feature vector:\")\n",
    "print(\" \", X1[0])\n",
    "print(\"\\t\\t      Predicted \\tCorrect\")\n",
    "print(\"Label(Y)\\t\\t \" + np.array2string(Y1[0]) + \"\\t\\t   -10\")\n",
    "print(\"Explanation (E) \\t \" + np.array2string(E1[0]) + \"\\t\\t   13\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [[3, 1, -11, -2, -2, -2, 296, 0]]\n",
    "\n",
    "## correct answers: Y:-11, E:25\n",
    "Y2, E2 = ted.predict_explain(X2)\n",
    "print(\"Predicting for feature vector:\")\n",
    "print(\" \", X2[0])\n",
    "\n",
    "print(\"\\t\\t      Predicted \\tCorrect\")\n",
    "print(\"Label(Y)\\t\\t \" + np.array2string(Y2[0]) + \"\\t\\t   -11\")\n",
    "print(\"Explanation (E) \\t \" + np.array2string(E2[0]) + \"\\t\\t   25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a more relevant human interface\n",
    "\n",
    "TED_CaresianExplainer can produce the correct explanation for a feature vector, but simply producing \"3\" as an explanation is not sufficient in most uses. This section shows one way to implement the mapping of real explanations to the explanation IDs that TED requires. This is inspired by the [FICO reason codes](https://www.fico.com/en/latest-thinking/product-sheet/us-fico-score-reason-codes), which are explanations for a FICO credit score.  \n",
    "\n",
    "In this case the explanations are text, but the same idea can be used to map explanation IDs to other formats, such as a file name containing an audio or video explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_Strings =[\"IS\", \"Approved for\"]\n",
    "def labelToString(label) :\n",
    "    if label == -10 :\n",
    "        return \"IS\"\n",
    "    else :\n",
    "        return \"IS NOT\"\n",
    "\n",
    "Explanation_Strings = [\n",
    "    \"Seeking Higher Salary in Org 1\",\n",
    "    \"Promotion Lag, Org 1, Position 1\",\n",
    "    \"Promotion Lag, Org 1, Position 2\",\n",
    "    \"Promotion Lag, Org 1, Position 3\",\n",
    "    \"Promotion Lag, Org 2, Position 1\",\n",
    "    \"Promotion Lag, Org 2, Position 2\",\n",
    "    \"Promotion Lag, Org 2, Position 3\",\n",
    "    \"Promotion Lag, Org 3, Position 1\",\n",
    "    \"Promotion Lag, Org 3, Position 2\",\n",
    "    \"Promotion Lag, Org 3, Position 3\",\n",
    "    \"New employee, Org 1, Position 1\",\n",
    "    \"New employee, Org 1, Position 2\",\n",
    "    \"New employee, Org 1, Position 3\",\n",
    "    \"New employee, Org 2, Position 1\",\n",
    "    \"New employee, Org 2, Position 2\",\n",
    "    \"Disappointing evaluation, Org 1\",\n",
    "    \"Disappointing evaluation, Org 2\",\n",
    "    \"Compensation does not match evaluations, Med rating\",\n",
    "    \"Compensation does not match evaluations, High rating\",\n",
    "    \"Compensation does not match evaluations, Org 1, Med rating\",\n",
    "    \"Compensation does not match evaluations, Org 2, Med rating\",\n",
    "    \"Compensation does not match evaluations, Org 1, High rating\",\n",
    "    \"Compensation does not match evaluations, Org 2, High rating\",\n",
    "    \"Mid-career crisis, Org 1\",\n",
    "    \"Mid-career crisis, Org 2\",\n",
    "    \"Did not match any retention risk rules\"]\n",
    "\n",
    "\n",
    "print(\"Employee #1 \" + labelToString(Y1[0]) + \" a retention risk with explanation: \" + Explanation_Strings[E1[0]])\n",
    "print()\n",
    "print(\"Employee #2 \" + labelToString(Y2[0]) + \" a retention risk with explanation: \" + Explanation_Strings[E2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ted2\"></a>\n",
    "## Overall model accuracy\n",
    "\n",
    "How well does TED_Cartesian do in predicting all test labels (Y) and explanations (E)?\n",
    "\n",
    "The \"score\" method of TED_Cartesian calculates this. The accuracy of predicting the combined YE labels could be of interest to researchers who want to better understand the inner workings of TED_Cartesian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YE_accuracy, Y_accuracy, E_accuracy = ted.score(X_test, Y_test, E_test)    # evaluate the classifier\n",
    "print(\"Evaluating accuracy of TED-enhanced classifier on test data\")\n",
    "print(' Accuracy of predicting Y labels: %.2f%%' % (100*Y_accuracy))\n",
    "print(' Accuracy of predicting explanations: %.2f%%' % (100*E_accuracy))\n",
    "print(' Accuracy of predicting Y + explanations: %.2f%%' % (100*YE_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is easy to use the TED_CartesianExplainer if you have a training dataset that contains explanations. The framework is general in that it can use any classification technique that follows the fit/predict paradigm, so that if you already have a favorite algorithm, you can use it with the TED framework.\n",
    "* The main advantage of this algorithm is that the quality of the explanations produced are exactly the same quality as those that the algorithm is trained on.  Thus, if you teach (train) the system well with good training data and good explanations, you will get good explanations out in a language you should understand.\n",
    "* The downside of this approach is that someone needs to create explanations. This should be straightforward when a domain expert is creating the initial training data: if they decide a loan should be rejected, they should know why, and if they do not, it may not be a good decision.\n",
    "* However, this may be more of a challenge when a training dataset already exists without explanations and now someone needs to create the explanations.  The original person who did the labeling of decisions may no longer be available, so the explanations for the decisions may not be known.  In this case, we argue, the system is in a dangerous state.  Training data exists that no one understands why it is labeled in a certain way.   Asking the model to explain one of its predictions when no person can explain an instance in the training data does not seem consistent.\n",
    "* Dealing with this situation is one of the open research problems that comes from the TED approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Home Equity Line of Credit (HELOC) Dataset**: anonymized information about home equity line of credit (HELOC) applications made by real homeowners. The customers in this dataset have requested a credit line in the range of USD 5,000 - 150,000. \n",
    "* Use the information about the applicant in their credit report to predict whether they will make timely payments over a two year period. The machine learning prediction can then be used to decide whether the homeowner qualifies for a line of credit and, if so, how much credit should be extended\n",
    "* The HELOC dataset and more information about it, including instructions to download, can be found [here](https://community.fico.com/s/explainable-machine-learning-challenge?tabset-3158a=2)\n",
    "\n",
    "Go to the next notebook: `HELOC.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
